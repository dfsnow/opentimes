---

name: calculate-times
run-name: calculate-times-${{ inputs.mode }}-${{ inputs.year }}-${{ inputs.geography }}-${{ inputs.state }}-${{ inputs.centroid_type }}

on:
  workflow_dispatch:
    inputs:
      # Input values match those in params.yaml
      mode:
        required: true
        description: Mode of travel in R5
        default: 'car'
        type: choice
        options:
          - car
          - bicycle
          - transit
          - walk

      year:
        required: true
        description: Census/OSM data year
        default: '2020'
        type: choice
        options:
          - '2020'
          - '2021'
          - '2022'
          - '2023'
          - '2024'

      geography:
        required: true
        description: Census data geography
        default: county
        type: choice
        options:
          - state
          - county
          - county_subdivision
          - tract
          - block_group
          - zcta

      state:
        required: true
        description: Target Census state
        default: '01'
        type: choice
        options:
          - '01'
          - '02'
          - '04'
          - '05'
          - '06'
          - '08'
          - '09'
          - '10'
          - '11'
          - '12'
          - '13'
          - '15'
          - '16'
          - '17'
          - '18'
          - '19'
          - '20'
          - '21'
          - '22'
          - '23'
          - '24'
          - '25'
          - '26'
          - '27'
          - '28'
          - '29'
          - '30'
          - '31'
          - '32'
          - '33'
          - '34'
          - '35'
          - '36'
          - '37'
          - '38'
          - '39'
          - '40'
          - '41'
          - '42'
          - '44'
          - '45'
          - '46'
          - '47'
          - '48'
          - '49'
          - '50'
          - '51'
          - '53'
          - '54'
          - '55'
          - '56'

      centroid_type:
        required: true
        description: Whether or not to use population-weighted locations
        default: weighted
        type: choice
        options:
          - weighted
          - unweighted

      override_chunks:
        required: false
        description: |
          Comma-separated chunks to run e.g. 0-5,6-11.
          Will run all chunks if null
        type: string

env:
  AWS_DEFAULT_REGION: us-east-1
  # See: https://github.com/aws/aws-cli/issues/5262#issuecomment-705832151
  AWS_EC2_METADATA_DISABLED: true
  PYTHONUNBUFFERED: "1"

jobs:
  # Using the location data, split the origins into N jobs (max 256)
  setup-jobs:
    runs-on: ubuntu-22.04
    outputs:
      chunks: ${{ steps.create-job-chunks.outputs.chunks }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Cloudflare credentials
        uses: ./.github/actions/setup-cloudflare-s3
        with:
          CLOUDFLARE_S3_API_ACCESS_KEY_ID: ${{ secrets.CLOUDFLARE_S3_API_ACCESS_KEY_ID }}
          CLOUDFLARE_S3_API_SECRET_ACCESS_KEY: ${{ secrets.CLOUDFLARE_S3_API_SECRET_ACCESS_KEY }}

      - name: Build Dockerized dependencies
        uses: ./.github/actions/build-docker
        with:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Fetch locations data
        uses: ./.github/actions/fetch-locations

      - name: Fetch R5 JAR
        uses: ./.github/actions/fetch-jar
        with:
          CLOUDFLARE_ACCOUNT_ID: ${{ vars.CLOUDFLARE_ACCOUNT_ID }}

      - name: Create job chunks
        id: create-job-chunks
        shell: bash
        run: |
          chunks=$(docker compose run --quiet-pull opentimes python3 ./src/split_origin.py \
            --year ${{ inputs.year }} --geography ${{ inputs.geography }} \
            --state ${{ inputs.state }})
          echo "chunks=$chunks" >> $GITHUB_OUTPUT

          # If override chunks are set, use those instead
          chunks_parsed=($(echo "$chunks" | jq -r '.[]'))
          if [ -n "${{ inputs.override_chunks }}" ]; then
            override_chunks_parsed=($(echo "${{ inputs.override_chunks }}" | tr -d ' ' | tr ',' ' '))
            for chunk in "${override_chunks_parsed[@]}"; do
              if [[ ! " ${chunks_parsed[@]} " =~ " ${chunk} " ]]; then
                echo "Error: Override chunk ${chunk} is not in the chunks for this origin"
                echo "Chunks include: ${chunks_parsed[@]}"
                exit 1
              fi
            done
            chunks_json=$(printf '%s\n' "${override_chunks_parsed[@]}" | jq -c -R . | jq -c -s .)
            echo "Creating jobs for chunks: ${override_chunks_parsed[@]}"
            echo "chunks=$chunks_json" > $GITHUB_OUTPUT
          else
            echo "Creating jobs for chunks: ${chunks_parsed[@]}"
          fi

  run-job:
    runs-on: ubuntu-22.04
    needs: setup-jobs
    strategy:
      # Don't fail all chunks if one fails
      fail-fast: false
      matrix:
        chunk: ${{ fromJSON(needs.setup-jobs.outputs.chunks) }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Cloudflare credentials
        uses: ./.github/actions/setup-cloudflare-s3
        with:
          CLOUDFLARE_S3_API_ACCESS_KEY_ID: ${{ secrets.CLOUDFLARE_S3_API_ACCESS_KEY_ID }}
          CLOUDFLARE_S3_API_SECRET_ACCESS_KEY: ${{ secrets.CLOUDFLARE_S3_API_SECRET_ACCESS_KEY }}

      - name: Fetch locations data
        uses: ./.github/actions/fetch-locations

      - name: Fetch R5 JAR
        uses: ./.github/actions/fetch-jar
        with:
          CLOUDFLARE_ACCOUNT_ID: ${{ vars.CLOUDFLARE_ACCOUNT_ID }}

      # Don't fetch network data because they're very large and will churn the
      # Actions cache. We want to wait to fetch it until jobs have actually
      # been picked up
      - name: Fetch network data
        uses: ./.github/actions/fetch-network
        with:
          year: ${{ inputs.year }}
          state: ${{ inputs.state }}

      - name: Run job chunk
        shell: bash
        working-directory: 'data'
        run: |
          docker compose run --quiet-pull opentimes Rscript ./src/calculate_times.R \
            --mode ${{ inputs.mode }} --year ${{ inputs.year }} \
            --geography ${{ inputs.geography }} --state ${{ inputs.state }} \
            --centroid_type ${{ inputs.centroid_type }} \
            --chunk ${{ matrix.chunk }} --write-to-s3

  clear-network-cache:
    runs-on: ubuntu-22.04
    needs: run-job
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Clear network cache
        shell: bash
        run: |
          gh cache delete \
            network-${{ inputs.year }}-${{ inputs.state }}-${{ hashFiles('./data/dvc.lock') }}
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
